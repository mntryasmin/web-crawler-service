# Web Crawler Service

Aplica√ß√£o Java que realiza buscas em websites por termos espec√≠ficos, rastreando links e listando as URLs onde o termo foi encontrado. Segue princ√≠pios SOLID e arquitetura em camadas.

## üõ† Tecnologias

- Java 14
- Spark Framework (Web Server)
- SLF4J + Logback (Logging)
- Gson (JSON)
- JUnit 5 (Testes)

## üèó Arquitetura

- **Controller**: Endpoints HTTP (`CrawlController`)
- **Service**: L√≥gica de neg√≥cio e crawling (`CrawlerService`)
- **Model**: Entidades e objetos de dom√≠nio
- **Configuration**: Propriedades e rotas (`ApplicationProperties`, `RouteConfiguration`)

## üìã Requisitos

- Docker (para executar via container) ou Maven + JDK 14 (para executar local)
- Porta 4567 dispon√≠vel (configur√°vel)

## ‚öôÔ∏è Configura√ß√£o

As propriedades ficam em `src/main/resources/application.properties` e podem ser sobrescritas por vari√°veis de ambiente.

Principais propriedades e valores padr√£o:

- `server.port=4567` (ENV: `PORT`)
- `base.url=http://hiring.axreng.com/` (ENV: `BASE_URL`)
- `crawler.max.depth=50`
- `crawler.idle.timeout=30000` (ms)
- `crawler.connect.timeout=5000` (ms)
- `crawler.read.timeout=5000` (ms)
- `crawler.timeout.seconds=30`
- `crawler.limit.results=true` ‚Üí ativa limite de resultados
- `crawler.max.results=100` ‚Üí quantidade m√°xima de URLs retornadas quando o limite est√° ativo

## üöÄ Como executar

### Via Docker

1) Build da imagem

```bash
docker build . -t axreng/backend
```

2) Executar o container

```bash
docker run -e BASE_URL=http://hiring.axreng.com/ -p 4567:4567 --rm axreng/backend
```

### Via Maven (local)

```bash
mvn clean compile exec:java
```

## üîç API Endpoints

### Iniciar nova busca

`POST /crawl`

Request:

```json
{ "keyword": "security" }
```

Response:

```json
{ "id": "30vbllyb" }
```

### Consultar resultados

`GET /crawl/{id}`

Response (exemplo):

```json
{
   "id": "30vbllyb",
   "status": "active",
   "urls": [
      "http://hiring.axreng.com/index2.html",
      "http://hiring.axreng.com/htmlman1/chcon.1.html"
   ]
}
```

## ÔøΩ Cole√ß√£o Postman

O projeto inclui uma cole√ß√£o do Postman (`web-crawler-service.postman_collection`) para facilitar os testes da API.

### Como usar:

1. Importe o arquivo `web-crawler-service.postman_collection` no Postman
2. Execute as requisi√ß√µes:
   - **"Start search"**: Inicia uma nova busca e salva automaticamente o ID retornado
   - **"Get search"**: Consulta os resultados usando o ID da busca anterior

A cole√ß√£o est√° configurada para ambientes LOCAL e PROD, facilitando o teste em diferentes cen√°rios.

## ÔøΩüìä Logs

**Console** 
N√≠veis: INFO, DEBUG, ERROR, WARN, TRACE.

## üß™ Testes

Executar testes unit√°rios:

```bash
mvn test
```

## ‚ö†Ô∏è Limita√ß√µes e Considera√ß√µes

1. Dados mantidos apenas em mem√≥ria (sem persist√™ncia ap√≥s rein√≠cio)
2. Sem pagina√ß√£o de resultados; pode haver limite por configura√ß√£o
3. Somente links do mesmo dom√≠nio de `base.url` s√£o seguidos